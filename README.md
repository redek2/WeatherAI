# WeatherAI

Aplikacja desktopowa (GUI) w jzyku Python, kt贸ra pobiera aktualne dane pogodowe i wykorzystuje lokalny model jzykowy (LLM) do generowania opisu pogody w jzyku naturalnym. Projekt wykorzystuje `customtkinter` do obsugi interfejsu u偶ytkownika oraz `llama-cpp-python` do inferencji modelu.

---

## 叼 Wersja Polska

### O projekcie

WeatherAI to aplikacja stworzona w celu eksploracji mo偶liwoci lokalnych modeli jzykowych (LLM) w praktycznym zastosowaniu. Aplikacja czy dane z zewntrznego API pogodowego (Open-Meteo) z bibliotek `llama-cpp-python` do generowania pynnych, naturalnych opis贸w na podstawie surowych danych.

Wersja ta posiada graficzny interfejs u偶ytkownika (GUI), kt贸ry pozwala na wygenerowanie raportu po klikniciu przycisku. Proces generowania AI odbywa si w osobnym wtku, dziki czemu aplikacja pozostaje responsywna.

### Zrzut ekranu

*(Zalecane: Wstaw tutaj zrzut ekranu aplikacji, aby pokaza GUI)*

`![WeatherAI GUI](./screenshot.png)`

### G贸wne funkcje

* **Graficzny Interfejs U偶ytkownika**: Prosty i nowoczesny interfejs (GUI) stworzony w `customtkinter`.
* **Pobieranie danych pogodowych**: Integracja z API Open-Meteo do pobierania aktualnych prognoz.
* **Wykrywanie lokalizacji**: Automatyczne wykrywanie lokalizacji u偶ytkownika na podstawie adresu IP (za pomoc `geocoder`) lub mo偶liwo rcznego ustawienia miasta w konfiguracji.
* **Lokalne generowanie AI**: Wykorzystanie `llama-cpp-python` do uruchamiania modeli LLM (w formacie GGUF) lokalnie na maszynie u偶ytkownika.
* **Wielowtkowo**: Proces generowania opisu przez AI dziaa w osobnym wtku, nie blokujc interfejsu u偶ytkownika.
* **Logowanie**: Szczeg贸owe logowanie zdarze do konsoli (z kolorami) oraz do pliku, w tym globalna obsuga wyjtk贸w.

### U偶yte technologie

* **Python 3.10+**
* **customtkinter**: Do budowy nowoczesnego interfejsu graficznego.
* **llama-cpp-python**: Do adowania i uruchamiania modeli LLM w formacie GGUF.
* **openmeteo-requests**: Klient API dla Open-Meteo.
* **geocoder**: Do automatycznego wykrywania lokalizacji na podstawie IP.
* **colorama**: Do kolorowania log贸w w konsoli.
* **requests-cache** & **retry-requests**: Do buforowania i ponawiania zapyta API.

### Instalacja i konfiguracja

**Wa偶ne**: Aby uruchomi projekt, konieczna jest rczna konfiguracja.

1.  **Klonuj repozytorium:**
    ```
    git clone [https://github.com/TWOJA_NAZWA_U呕YTKOWNIKA/WeatherAI.git](https://github.com/TWOJA_NAZWA_U呕YTKOWNIKA/WeatherAI.git)
    cd WeatherAI
    ```

2.  **Stw贸rz i aktywuj wirtualne rodowisko** (zalecane):
    ```
    python -m venv venv
    source venv/bin/activate  # Na Windows: venv\Scripts\activate
    ```

3.  **Zainstaluj wymagane biblioteki:**
    ```
    pip install -r requirements.txt
    ```

4.  **Pobierz model LLM:**
    * Projekt wymaga modelu jzykowego w formacie **GGUF**.
    * Mo偶esz pobra model kompatybilny z `llama.cpp`, na przykad jeden z modeli "Bielik" z Hugging Face.
    * Umie pobrany plik `.gguf` w folderze `models/` (utw贸rz ten folder, jeli nie istnieje).

5.  **Skonfiguruj aplikacj (Kluczowy krok):**
    * Znajd藕 plik `config_template.py` w g贸wnym katalogu.
    * Stw贸rz kopi tego pliku i zmie jej nazw na `config.py`.
    * Otw贸rz `config.py` w edytorze tekstu.
    * Zaktualizuj zmienn `MODEL_SHORT`, aby wskazywaa na plik Twojego modelu, np.:
        ```python
        MODEL_SHORT = os.path.join(MODEL_PATH, "Bielik-11B-v2.6-Instruct.Q4_K_M.gguf")
        ```
    * Dostosuj `SYSTEM_PROMPT` i `USER_PROMPT` do swoich potrzeb lub innego modelu.
    * Dodaj wasne predefiniowane miasta do sownika `CITIES`, lub odkomentuj funkcj dotyczc lokalizacji.

### Uruchamianie

Po poprawnej instalacji i konfiguracji, uruchom aplikacj za pomoc pliku `gui.py`:

python gui.py
# WeatherAI

A desktop application (GUI) in Python that fetches current weather data and uses a local language model (LLM) to generate a weather description in natural language. The project uses `customtkinter` for the user interface and `llama-cpp-python` for model inference.

---

##  English Version

### About The Project

WeatherAI is an application created to explore the possibilities of local language models (LLMs) in a practical application. The application combines data from an external weather API (Open-Meteo) with the `llama-cpp-python` library to generate fluent, natural descriptions from raw data.

This version features a graphical user interface (GUI) that allows generating a report at the click of a button. The AI generation process runs in a separate thread, ensuring the application remains responsive.

### Screenshot

*(Recommended: Insert a screenshot of the application here to showcase the GUI)*

`![WeatherAI GUI](./screenshot.png)`

### Key Features

* **Graphical User Interface**: A simple and modern interface (GUI) created in `customtkinter`.
* **Weather Data Fetching**: Integration with the Open-Meteo API to download current forecasts.
* **Location Detection**: Automatic detection of the user's location based on IP address (using `geocoder`) or the ability to manually set a city in the configuration.
* **Local AI Generation**: Use of `llama-cpp-python` to run LLM models (in GGUF format) locally on the user's machine.
* **Multi-threading**: The AI description generation process runs in a separate thread, not blocking the user interface.
* **Logging**: Detailed logging of events to the console (with colors) and to a file, including global exception handling.

### Technologies Used

* **Python 3.10+**
* **customtkinter**: For building the modern graphical interface.
* **llama-cpp-python**: For loading and running LLM models in GGUF format.
* **openmeteo-requests**: API client for Open-Meteo.
* **geocoder**: For automatic IP-based location detection.
* **colorama**: For coloring console logs.
* **requests-cache** & **retry-requests**: For caching and retrying API requests.

### Installation and Configuration

**Important**: Manual configuration is required to run the project.

1.  **Clone the repository:**
    ```bash
    git clone [https://github.com/YOUR_USERNAME/WeatherAI.git](https://github.com/YOUR_USERNAME/WeatherAI.git)
    cd WeatherAI
    ```

2.  **Create and activate a virtual environment** (recommended):
    ```bash
    python -m venv venv
    source venv/bin/activate  # On Windows: venv\Scripts\activate
    ```

3.  **Install the required libraries:**
    ```bash
    pip install -r requirements.txt
    ```

4.  **Download an LLM Model:**
    * The project requires a language model in **GGUF format**.
    * You can download a `llama.cpp`-compatible model, for example, one of the "Bielik" models from Hugging Face.
    * Place the downloaded `.gguf` file in the `models/` folder (create this folder if it doesn't exist).

5.  **Configure the Application (Key Step):**
    * Find the `config_template.py` file in the main directory.
    * Create a copy of this file and rename it to `config.py`.
    * Open `config.py` in a text editor.
    * Update the `MODEL_SHORT` variable to point to your model's file, e.g.:
        ```python
        MODEL_SHORT = os.path.join(MODEL_PATH, "Bielik-11B-v2.6-Instruct.Q4_K_M.gguf")
        ```
    * Adjust `SYSTEM_PROMPT` and `USER_PROMPT` to your needs or a different model.
    * Add your own predefined cities to the `CITIES` dictionary, or uncomment the function related to location.

### Usage

After correct installation and configuration, run the application using the `gui.py` file:

```
python gui.py